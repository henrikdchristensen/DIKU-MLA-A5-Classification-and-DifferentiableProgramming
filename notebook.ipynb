{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sleep well (35 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "X_train = pd.read_csv('data\\Sleep-EDF-15_U-Time/X_train.csv', header=None)\n",
    "y_train = pd.read_csv('data\\Sleep-EDF-15_U-Time/y_train.csv', header=None)\n",
    "X_test = pd.read_csv('data\\Sleep-EDF-15_U-Time/X_test.csv', header=None)\n",
    "y_test = pd.read_csv('data\\Sleep-EDF-15_U-Time/y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data understanding and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies for training data:\n",
      "Class (0.0,): 52.09%\n",
      "Class (2.0,): 25.27%\n",
      "Class (1.0,): 9.55%\n",
      "Class (4.0,): 8.39%\n",
      "Class (3.0,): 4.69%\n"
     ]
    }
   ],
   "source": [
    "# Calculate class frequencies for training dat, normalized to [0,1]\n",
    "class_frequencies = y_train.value_counts(normalize=True)\n",
    "\n",
    "# Print each class frequency for training data\n",
    "print(\"Class frequencies for training data:\")\n",
    "for label, freq in class_frequencies.items():\n",
    "    print(f\"Class {label}: {freq*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, zero_one_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_classifier(y_true_train, y_pred_train, y_true_test, y_pred_test, classifier_name):\n",
    "    print(f\"Evaluation Metrics for {classifier_name}:\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"Training:\\n {confusion_matrix(y_true_train, y_pred_train)}\")\n",
    "    print(f\"Test:\\n {confusion_matrix(y_true_test, y_pred_test)}\")\n",
    "\n",
    "    # Zero-One Loss\n",
    "    print(f\"\\nZero-One Loss:\")\n",
    "    print(f\"Training: {zero_one_loss(y_true_train, y_pred_train):.3f}\")\n",
    "    print(f\"Test: {zero_one_loss(y_true_test, y_pred_test):.3f}\")\n",
    "\n",
    "    # Accuracy\n",
    "    print(f\"\\nAccuracy\")\n",
    "    print(f\"Training: {accuracy_score(y_true_train, y_pred_train):.3f}\")\n",
    "    print(f\"Test: {accuracy_score(y_true_test, y_pred_test):.3f}\")\n",
    "\n",
    "    # Precision\n",
    "    print(f\"\\nPrecision:\")\n",
    "    print(f\"Training: {precision_score(y_true_train, y_pred_train, average='macro'):.3f}\")\n",
    "    print(f\"Test: {precision_score(y_true_test, y_pred_test, average='macro'):.3f}\")\n",
    "\n",
    "    # Recall\n",
    "    print(f\"\\nRecall:\")\n",
    "    print(f\"Training: {recall_score(y_true_train, y_pred_train, average='macro'):.3f}\")\n",
    "    print(f\"Test: {recall_score(y_true_test, y_pred_test, average='macro'):.3f}\")\n",
    "\n",
    "    # F1 Score\n",
    "    print(f\"\\nF1 Score:\")\n",
    "    print(f\"Training: {f1_score(y_true_train, y_pred_train, average='macro'):.3f}\")\n",
    "    print(f\"Test: {f1_score(y_true_test, y_pred_test, average='macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-nominal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Logistic Regression:\n",
      "\n",
      "Confusion Matrix:\n",
      "Training:\n",
      " [[16993   404    37    12   120]\n",
      " [  532  1322  1012     5   350]\n",
      " [   62   446  7226   314   475]\n",
      " [   10     7   662   896     8]\n",
      " [   64   180   342     0  2245]]\n",
      "Test:\n",
      " [[7437  124    9    3    6]\n",
      " [  78  412  182    1  102]\n",
      " [  15  188 3376   83  179]\n",
      " [   0    0  135  260    0]\n",
      " [  53  161   59    0 1038]]\n",
      "\n",
      "Zero-One Loss:\n",
      "Training: 0.150\n",
      "Test: 0.099\n",
      "\n",
      "Accuracy\n",
      "Training: 0.850\n",
      "Test: 0.901\n",
      "\n",
      "Precision:\n",
      "Training: 0.747\n",
      "Test: 0.775\n",
      "\n",
      "Recall:\n",
      "Training: 0.717\n",
      "Test: 0.768\n",
      "\n",
      "F1 Score:\n",
      "Training: 0.727\n",
      "Test: 0.771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Build and train the model\n",
    "logistic_model = LogisticRegression(max_iter=10000)  # Default is L2 regularization\n",
    "logistic_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict and evaluate\n",
    "train_pred = logistic_model.predict(X_train)\n",
    "test_pred = logistic_model.predict(X_test)\n",
    "\n",
    "evaluate_classifier(y_train, train_pred, y_test, test_pred, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Random Forest (n_estimators=50):\n",
      "\n",
      "Confusion Matrix:\n",
      "Training:\n",
      " [[17566     0     0     0     0]\n",
      " [    6  3214     1     0     0]\n",
      " [    0     0  8522     0     1]\n",
      " [    0     0     1  1582     0]\n",
      " [    0     0     0     0  2831]]\n",
      "Test:\n",
      " [[7448  109   13    2    7]\n",
      " [ 110  395  174    1   95]\n",
      " [  24  228 3346   78  165]\n",
      " [   0    0  177  218    0]\n",
      " [ 125  161   95    0  930]]\n",
      "\n",
      "Zero-One Loss:\n",
      "Training: 0.000\n",
      "Test: 0.113\n",
      "\n",
      "Accuracy\n",
      "Training: 1.000\n",
      "Test: 0.887\n",
      "\n",
      "Precision:\n",
      "Training: 1.000\n",
      "Test: 0.759\n",
      "\n",
      "Recall:\n",
      "Training: 0.999\n",
      "Test: 0.725\n",
      "\n",
      "F1 Score:\n",
      "Training: 1.000\n",
      "Test: 0.739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for n_trees in [50, 100, 200]:\n",
    "    # Build and train the model\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_trees)\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    train_pred = rf_model.predict(X_train)\n",
    "    test_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_classifier(y_train, train_pred, y_test, test_pred, f\"Random Forest (n_estimators={n_trees})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest-Neighbor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hdc\\Google Drive Streaming\\My Drive\\KU\\5. semester\\Machine Learning A (MLA)\\Assignments\\5\\repo\\notebook.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hdc/Google%20Drive%20Streaming/My%20Drive/KU/5.%20semester/Machine%20Learning%20A%20%28MLA%29/Assignments/5/repo/notebook.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hdc/Google%20Drive%20Streaming/My%20Drive/KU/5.%20semester/Machine%20Learning%20A%20%28MLA%29/Assignments/5/repo/notebook.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(knn, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)  \u001b[39m# 5-fold cross-validation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hdc/Google%20Drive%20Streaming/My%20Drive/KU/5.%20semester/Machine%20Learning%20A%20%28MLA%29/Assignments/5/repo/notebook.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mravel())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hdc/Google%20Drive%20Streaming/My%20Drive/KU/5.%20semester/Machine%20Learning%20A%20%28MLA%29/Assignments/5/repo/notebook.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Train the model with the best number of neighbors\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hdc/Google%20Drive%20Streaming/My%20Drive/KU/5.%20semester/Machine%20Learning%20A%20%28MLA%29/Assignments/5/repo/notebook.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_knn \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:444\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_passthrough_scorer\u001b[39m(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    443\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39;49mscore(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\base.py:668\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:252\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mfor\u001b[39;00m k, classes_k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes_):\n\u001b[0;32m    251\u001b[0m     \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m         mode, _ \u001b[39m=\u001b[39m _mode(_y[neigh_ind, k], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    253\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m         mode, _ \u001b[39m=\u001b[39m weighted_mode(_y[neigh_ind, k], weights, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\sklearn\\utils\\fixes.py:169\u001b[0m, in \u001b[0;36m_mode\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mode\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    168\u001b[0m     \u001b[39mif\u001b[39;00m sp_version \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m parse_version(\u001b[39m\"\u001b[39m\u001b[39m1.9.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 169\u001b[0m         mode \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mstats\u001b[39m.\u001b[39;49mmode(a, axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    170\u001b[0m         \u001b[39mif\u001b[39;00m sp_version \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m parse_version(\u001b[39m\"\u001b[39m\u001b[39m1.10.999\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    171\u001b[0m             \u001b[39m# scipy.stats.mode has changed returned array shape with axis=None\u001b[39;00m\n\u001b[0;32m    172\u001b[0m             \u001b[39m# and keepdims=True, see https://github.com/scipy/scipy/pull/17561\u001b[39;00m\n\u001b[0;32m    173\u001b[0m             \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:591\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[39mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[39m*\u001b[39msamples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    590\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmoveaxis(x, axis, \u001b[39m0\u001b[39m)\n\u001b[1;32m--> 591\u001b[0m res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(hypotest_fun, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, arr\u001b[39m=\u001b[39;49mx)\n\u001b[0;32m    592\u001b[0m res \u001b[39m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n\u001b[0;32m    593\u001b[0m \u001b[39mreturn\u001b[39;00m tuple_to_result(\u001b[39m*\u001b[39mres)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\numpy\\lib\\shape_base.py:402\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m buff[ind0] \u001b[39m=\u001b[39m res\n\u001b[0;32m    401\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m inds:\n\u001b[1;32m--> 402\u001b[0m     buff[ind] \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind], \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(res, matrix):\n\u001b[0;32m    405\u001b[0m     \u001b[39m# wrap the array, to preserve subclasses\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     buff \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39m__array_wrap__(buff)\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:588\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper.<locals>.hypotest_fun\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[39mif\u001b[39;00m is_too_small(samples):\n\u001b[0;32m    587\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mfull(n_out, np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m--> 588\u001b[0m \u001b[39mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[39m*\u001b[39;49msamples, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:517\u001b[0m, in \u001b[0;36mmode\u001b[1;34m(a, axis, nan_policy, keepdims)\u001b[0m\n\u001b[0;32m    514\u001b[0m     NaN \u001b[39m=\u001b[39m _get_nan(a)\n\u001b[0;32m    515\u001b[0m     \u001b[39mreturn\u001b[39;00m ModeResult(\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39marray([NaN, \u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mNaN\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m--> 517\u001b[0m vals, cnts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(a, return_counts\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    518\u001b[0m modes, counts \u001b[39m=\u001b[39m vals[cnts\u001b[39m.\u001b[39margmax()], cnts\u001b[39m.\u001b[39mmax()\n\u001b[0;32m    519\u001b[0m \u001b[39mreturn\u001b[39;00m ModeResult(modes[()], counts[()])\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hdc\\AppData\\Local\\miniconda3\\envs\\mypy\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:328\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unique1d\u001b[39m(ar, return_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, return_inverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    324\u001b[0m               return_counts\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    Find the unique elements of an array, ignoring shape.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    330\u001b[0m     optional_indices \u001b[39m=\u001b[39m return_index \u001b[39mor\u001b[39;00m return_inverse\n\u001b[0;32m    332\u001b[0m     \u001b[39mif\u001b[39;00m optional_indices:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'n_neighbors': list(range(1, 31))}  # Considering 1 to 30 neighbors\n",
    "\n",
    "# Use GridSearchCV to find the best number of neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)  # 5-fold cross-validation\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Train the model with the best number of neighbors\n",
    "best_knn = grid_search.best_estimator_\n",
    "train_pred = best_knn.predict(X_train)\n",
    "test_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_classifier(y_train, train_pred, y_test, test_pred, \"K-Nearest Neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariance and normalization (30 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
